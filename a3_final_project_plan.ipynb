{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea5028a5-e497-43b9-95d9-d54b9d559a0f",
    "_uuid": "e2e867859acbb5fc5b62f8a8a59439f3d1d7746c",
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Need of the day:People Analytics \n",
    "** Analyze your own employees to identify voluntary attrition **\n",
    "***\n",
    "** \"Clients do not come first. Employees come first. If you take care of employees, they will take care of the clients\" - Richard Branson**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28284afb-1322-4651-935a-332efe986684",
    "_uuid": "39286a6433ae87ba47f96461c381c6b36b9e63c3",
    "deletable": true,
    "editable": true
   },
   "source": [
    "**\"I quit...\"**, No employer wants to hear these words, but it seems more and more employers get to hear this as employees are leaving for greener pastures. In today’s world, employers have to take enormous efforts to retain their high skilled employees. Per latest statistics from Bureau of labor[2], voluntary quits rose in professional and business services by 82,000. Hence a million-dollar question for an employer is: How can one gauge the signs of flight risk long before a high performer starts looking for a new position? Is there a systematic pattern or trend which can be analyzed to preemptively avoid quits? Can we turn to data and predict which employee will leave and why? If these questions can be answered using data then the employer can give incentives to the employees at risk of leaving. Its a win win situation for both the employer and employee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Motivation for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Even though companies have perennially faced the problem of attrition, using data to analyze employees and predict attrition is fairly new. Even tech companies with huge data infrastructure never thought of applying data analytics on their own employees. I got interested in this problem while doing literature survey for my capstone project. I found countless articles on linked in to analyze and predict employee turnover. Most of the literature written on People analytics is in the last 5 years. I found this very surprising as business intelligence has been used to solve various business problems for decades [3]. I wanted to create a quick prototype of a statistical model to predict attrition. Since employee data can be huge for big organizations and the number of features required to predict attrition may vary from domain to domain, I was looking for a simpler and smaller dataset to start with. I found this Kaggle competition[1] with simulated dataset[9] as perfect for my requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Human-centered design considerations which inform my decision to pursue this project**\n",
    "\n",
    "Data science is a revolution. The more we can solve human centered problems using data and apply scientifc methods in analysing and predicting human data, the better it is for humanity. As per quote from Yogi Berra: “It's tough to make predictions, especially about the future.” One would wonder how difficult it would be then to make predictions about people? This project can provide intriguing insights on what people value the most in their job: whether its money or the number of hours they put in job or how well they are evaluated or the number of projects they work for in a year. Once these insights are gained, results from People Analytics can be useful for improving the managerial level decisions like which factors should be considered to improve the satisfaction level of employees, how to strengthen the relationship between leadership and staff or how much budget should be sanctioned to organize morale events at the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a32307f-5710-4755-8e17-b18532bd617d",
    "_uuid": "e786ac2910dbd798f5ef96dc7227f0500d3bda57",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining the Research Questions\n",
    "***\n",
    "We aim to answer these questions by applying data science on employee data.\n",
    " * Question 1: Which employees are most likely to leave voluntarily? \n",
    " * Question 2: What are the reasons for the employees to leave?\n",
    " * Question 3: How to retain these employees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "***\n",
    " * Hypothesis 1: High performers(good last_evaluation) and low performers(poor last_evaluation) are most likely to leave.\n",
    " * Hypothesis 2: Even though 'satisfaction_level' seems to be a giveaway for an employees intent to leave, there are other predictors as strongly correlated to attrition rate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Dataset\n",
    "***\n",
    "### 1a. Data Source and License information\n",
    "The data has been borrowed from Kaggle competition [Human Resources Analytics]('https://www.kaggle.com/ludobenistant/hr-analytics/data'). This dataset is released under CC BY-SA 4.0, the details of this license can be found [here]('https://creativecommons.org/licenses/by-sa/4.0/'). There are 15000 observations in the dataset with 10 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Get a glimpse of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame.from_csv('HR_comma_sep.csv', index_col=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1c. Data Cleaning\n",
    "\n",
    "As shown above the data is fairly neat. Although there is no data processing needed for the dataset, I plan to change few column names which are misleading. For example 'sales' column is actually the department name for the employee. Similarly 'left' column indicates if the employee has left. Since'left' will be the target variable for building the attrition model, will rename it to 'attrition'. I also plan to find if there are any missing values in data and how to fill them. Will also need to check if any typecasting needs to be done for a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a46b6c64-6f25-4007-9f41-4abd863b0130",
    "_uuid": "db8d6c6327671959fae8eefb9e3e60adad46afbe",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Statistical Analysis\n",
    "***\n",
    "Once data is cleaned up and ready to use, will apply certain analytical methods to get a sense of data. Once the data is summarized, will perform corrleation analysis to identify features which will be consumed by the classification model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b25ecb0e-e300-4a72-b6fd-35ae93e020b8",
    "_uuid": "f664a189a3b1d04813b5223274b31ea7a14e8438",
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2a. Descriptive Statistics\n",
    "First step is to summarize data and find distribution of features in the dataset. For this purpose I would perform Descriptive statistics on data. As a part of descriptive statistics, will find mean, median, standard deviation, min, max, 25th and 75th percentile of columns with quantitaive values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "918f20ff-ed2c-43dd-849c-b7d751aeed86",
    "_uuid": "bed79decbf6495197f8f0219212c41c0042e196e",
    "deletable": true,
    "editable": true
   },
   "source": [
    "###  2b. Correlation Analysis\n",
    "Secondly would try to find the features which are most correlated to attrition. This can be done by doing correlation analysis of all features. Will create a correlation matrix and correlation heatmap to find what features will affect our target variable(attrition rate) the most. Correlation analysis would help us find which features are positively correlated and which ones are negatively correlated with attrition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07c80149-7a46-403c-b64a-ab536de68d01",
    "_uuid": "6bb2ec011a232193b96ff01e3852bef48a712e88",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Feature Engineering\n",
    "***\n",
    "Plan to extract top 5 features based on corelation analysis. The top 5 features which are most correlated to attrition will be used in the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ccf20c1a-d8da-4001-90f3-ae314d1f87a0",
    "_uuid": "90367f2beb5a2313ca2eee5d7f78d4afd49fc0d2",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Training the model\n",
    "***\n",
    "Will use logistic regression to classify employees on the basis of their probability to leave. Given our reserach questions, this is an ideal model to use for couple of reasons. First, its a very simple model and python provides ready to use package to apply logistic regression(sklearn.linear_model.LogisticRegression)[10]. Secondly since we not only need to do the classification, but we also want to find the probabilities to group the employees in different bands based on their risk of leaving, we can get the probabilities using sklearn.linear_model.LogisticRegression method 'predict_proba(X)'.To assess the quality of the model, available data will be divided into appropriately sized training and test sets, and these will be varied randomly to insure that the models thus constructed have an optimum trade off of low variance versus low bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Classifying employees using Logistic Regression\n",
    "Logistic Regression commonly deals with the issue of how likely an observation is to belong to each group. This model is commonly used to predict the likelihood of an event occurring. In contrast to linear regression, the output of logistic regression is transformed with a logit function. This makes the output either 0 or 1. This is a useful model to take advantage of for this problem because we are interested in predicting whether an employee will leave (0) or stay (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3269fcd-283b-43ff-bf67-be5900214c89",
    "_uuid": "1e506366a833f0a732716d1593d2c1cb7330fe5f",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Retention Plan Using Logistic Regression\n",
    "***\n",
    "We can also use logistic regression to predict probabilities. Once we have probability values from logistic regression, we can use these values to classify employees in different bands:\n",
    "\n",
    "1.\t**Extremely likely** – Employees with highest probability of leaving(>90%). \n",
    "2.\t**Moderately likely** – Employees with medium probability of leaving (50%< p< 90%).\n",
    "3.\t**Least likely** – Employees with less than 50% probability of leaving(<50%). \n",
    "\n",
    "Having identified employees with high risk of leaving, employer can take necessary actions to retain the employee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Limitations\n",
    "* One of the biggest limitation of this dataset is that it does not have data from multiple time stamps. If we had a time element in data, we could have estimated the probability of employee attrition over time. Survival analysis[8] would have been a great statistical measure for this purpose.\n",
    "* This is a simulated dataset with very limited number of features. Thus, this model will act more like a prototype for building more complex models on real life data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5edf8013-9379-4d38-a76d-c9047bb1862e",
    "_uuid": "96e9273f5e366d479e71c1f1b5555cbbdc02abd2",
    "deletable": true,
    "editable": true
   },
   "source": [
    "## References\n",
    "***\n",
    "* [1] Kaggle project https://www.kaggle.com/ludobenistant/hr-analytics\n",
    "* [2] Latest report from Bureau of Labour https://www.bls.gov/news.release/jolts.nr0.htm \n",
    "* [3] History of business intelligence https://www.betterbuys.com/bi/history-of-business-intelligence/\n",
    "* [4] Article on solving attrition with data https://towardsdatascience.com/solving-staff-attrition-with-data-3f09af2694cd \n",
    "* [5] Article on descriptive statistics https://www.marsja.se/pandas-python-descriptive-statistics/ \n",
    "* [6] Helpful linked in artcile on predicting employee attrition https://www.linkedin.com/pulse/predicting-employee-attrition-who-quit-when-praful-tickoo/\n",
    "* [7] Helpful linked in artciles on predicting employee attrition  https://www.linkedin.com/pulse/analyzing-employee-turnover-predictive-methods-richard-rosenow-pmp/\n",
    "* [8] Use of Survival analysis for predicting attrition https://www.slideshare.net/twbriggs/survival-analysis-for-predicting-employee-turnover/24\n",
    "* [9] Kaggle dataset https://www.kaggle.com/ludobenistant/hr-analytics/data\n",
    "* [10]sklearn logistic regression http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "* Link to the license for data https://creativecommons.org/licenses/by-sa/4.0/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
